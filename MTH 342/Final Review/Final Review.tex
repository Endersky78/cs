\documentclass[12pt, letterpaper]{article}
\setlength{\parindent}{0cm}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}

\title{Final Review}
\author{Jackson Hart}
\date{March 16th, 2022}

\begin{document}

\maketitle

\section*{Problem 2}
\subsection*{A)}
Let $v_1 = \begin{bmatrix} 1 & 2 & -2 & 1 \end{bmatrix}^T, v_2 = \begin{bmatrix} 9 & 12 & -4 & 9 \end{bmatrix}^T, v_3 = \begin{bmatrix} 1 & 3 & -3 & 1 \end{bmatrix}^T, v_4 = \begin{bmatrix} 1 & 3 & -2 & 1 \end{bmatrix}^T, v_5 = \begin{bmatrix} 4 & 3 & -1 & 4 \end{bmatrix}^T, v_6 = \begin{bmatrix} 1 & 3 & -2 & -1 \end{bmatrix}$ be vectors in $\mathbb{R}^4$. To find a basis for the span of these vectors, I'll place them into columns of a matrix and find the REF.

\[ \begin{bmatrix} 1 & 9 & 1 & 1 & 4 & 6 \\ 2 & 12 & 3 & 3 & 3 & 3 \\ -2 & -4 & -3 & -2 & -1 & -2 \\ 1 & 9 & 1 & 1 & 4 & -1 \end{bmatrix} \xrightarrow{Semi-REF} \begin{bmatrix} 1 & 9 & 1 & 1 & 4 & 6 \\ 0 & -6 & 1 & 1 & -5 & 3 \\ 0 & 0 & -4/3 & -1/3 & 5/3 & -10/3 \\ 0 & 0 & 0 & 0 & 0 & -7 \end{bmatrix} \]

Which then gives us the basis

\[ \begin{Bmatrix} \begin{bmatrix} 1 \\ 2 \\ -2 \\ 1 \end{bmatrix} & \begin{bmatrix} 9 \\ 12 \\ -4 \\ 9 \end{bmatrix} & \begin{bmatrix} 1 \\ 3 \\ -3 \\ 1 \end{bmatrix} & \begin{bmatrix} 1 \\ 3 \\ -2 \\ -1 \end{bmatrix} \end{Bmatrix} \]

\subsection*{B)}
Let $v_1 = \begin{bmatrix} 2 & -1 & 1 & 5 & -3 \end{bmatrix}^T, v_2 = \begin{bmatrix} 3 & -2 & 0 & 0 & 0 \end{bmatrix}^T, v_3 = \begin{bmatrix} 1 & 1 & 50 & -921 & 0 \end{bmatrix}^T$. We can determine if these vectors are linearly independent by putting them as columns of a matrix and finding its REF.

\[ \begin{bmatrix} 2 & 3 & 1 \\ -1 & -2 & 1 \\ 1 & 0 & 50 \\ 5 & 0 & -921 \\ -3 & 0 & 0 \end{bmatrix} \xrightarrow{REF} \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix}  \]

So they are linearly independent. If we were to add the two vectors $v_4 = \begin{bmatrix} 0 & 0 & 0 & 1 & 0 \end{bmatrix}^T \text{ and } v_5 = \begin{bmatrix} 0 & 0 & 0 & 0 & 1 \end{bmatrix}^T$. This set would be a basis for $\mathbb{R}^5$.

\section*{Problem 3}
Let $n > 0$ be odd and $A, B \in M_{nxn}(\mathbb{C})$ be such that $AB = -BA$. $A$ and $B$ are not invertible.

\begin{proof}
If $A$ and $B$ are invertible, 

\[ \text{Det}(A^{-1}) = \frac{1}{\text{Det}(A)} \]
\[ \text{Det}(B^{-1}) = \frac{1}{\text{Det}(B)} \]

So,

\[ \text{Det}((AB)^{-1}) = \frac{1}{\text{Det}(-BA)} \]
\[ \text{Det}(B^{-1}A^{-1}) = \frac{1}{\text{Det}(-B) \text{Det}(A)} \]
\[ \text{Det}(B^{-1}A^{-1}) = -1^n \text{Det}(B^{-1}) \text{Det}(A^{-1}) \]

And because $n$ is odd, 

\[ \text{Det}(B^{-1}A^{-1}) = -1 \times \text{Det}(B^{-1}A^{-1}) \]

So Det$((AB)^{-1})$ has to be equal to 0. Thus they are not invertible. 
\end{proof}

\section*{Problem 4}
Suppose $A$ is an $n \times n$ diagonalizable matrix that has only $\lambda = 1$ as an eigenvalue. Every nonzero vector in $\mathbb{R}^n$ is an eigenvector of $A$ corresponding to eigenvalue $\lambda = 1$. 

\begin{proof}
If $A$ is a square diagonalizable matrix and has one eigenvalue, then it can be said that $\lambda = 1$ has a algebraic multiplicity of $n$. And because $A$ is diagonalizable, then it can also be said that dim$(E_\lambda(\mathbb{R})) = n$. And thus, every nonzero vector in $\mathbb{R}^n$ is an eigenvector of $A$.

OR

\[ A = QDQ^{-1} \]
\[ A = QIQ^{-1} \]
\[ A = QQ^{-1} \]

And because $Q$ is invertible, it's linearly independent, and because it's n-dim'd, span$(Q) = \mathbb{R}^n$. and beacuse Q contains a basis for the eigenvectors of $A$, blah blah. 
\end{proof}

\section*{Problem 5}



\end{document}